{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate accuracy of vision model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Finding the nea image names where i last stopped evaluating on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total items in json file: 322\n",
      "total unique items in json file: 271\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data_cleaned = json.loads(open('./data.json').read())\n",
    "item_names = [i['item'] for i in data_cleaned]\n",
    "print(f'total items in json file: {len(item_names)}')\n",
    "print(f'total unique items in json file: {len(set(item_names))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>predictions</th>\n",
       "      <th>similarity</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>manual evaluation</th>\n",
       "      <th>remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../images/test/batch1/Bedsheet (2).jpg</td>\n",
       "      <td>Bedsheet</td>\n",
       "      <td>['Bedsheet']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../images/test/batch1/Bedsheet (3).jpg</td>\n",
       "      <td>Bedsheet</td>\n",
       "      <td>['Bedsheet']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../images/test/batch1/Bedsheet (4).jpg</td>\n",
       "      <td>Bedsheet</td>\n",
       "      <td>['Bedsheet']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../images/test/batch1/Bedsheet (5).jpg</td>\n",
       "      <td>Bedsheet</td>\n",
       "      <td>['Bedsheet']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../images/test/batch1/Bedsheet (6).jpg</td>\n",
       "      <td>Bedsheet</td>\n",
       "      <td>['Bedsheet']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 filename ground_truth   predictions  \\\n",
       "0  ../images/test/batch1/Bedsheet (2).jpg     Bedsheet  ['Bedsheet']   \n",
       "1  ../images/test/batch1/Bedsheet (3).jpg     Bedsheet  ['Bedsheet']   \n",
       "2  ../images/test/batch1/Bedsheet (4).jpg     Bedsheet  ['Bedsheet']   \n",
       "3  ../images/test/batch1/Bedsheet (5).jpg     Bedsheet  ['Bedsheet']   \n",
       "4  ../images/test/batch1/Bedsheet (6).jpg     Bedsheet  ['Bedsheet']   \n",
       "\n",
       "   similarity  evaluation  manual evaluation remarks  \n",
       "0         1.0         1.0                1.0     NaN  \n",
       "1         1.0         1.0                1.0     NaN  \n",
       "2         1.0         1.0                1.0     NaN  \n",
       "3         1.0         1.0                1.0     NaN  \n",
       "4         1.0         1.0                1.0     NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./manual_evaluation_with_similar_items.csv')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "evaluated_names = df['ground_truth'].unique()\n",
    "print(len(evaluated_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_to_evaluate = set(item_names).difference(set(evaluated_names))\n",
    "len(names_to_evaluate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36531365313653136"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "99/271"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to csv\n",
    "import csv\n",
    "with open('names_to_evaluate.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['name'])\n",
    "    writer.writerows([[name] for name in names_to_evaluate])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Paper',\n",
       " 'Paper bag',\n",
       " 'Paper box',\n",
       " 'Paper cup',\n",
       " 'Paper disposables',\n",
       " 'Printed paper (Glossy and non-glossy)']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [\n",
    "        \"Paper\",\n",
    "        \"Paper bag\",\n",
    "        \"Paper box\",\n",
    "        \"Paper cup\",\n",
    "        \"Paper disposables\",\n",
    "        \"Printed paper (Glossy and non-glossy)\"\n",
    "    ]\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the unique item names in data json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'material': 'Paper',\n",
       "  'item': 'Printed paper (Glossy and non-glossy)',\n",
       "  'recyclable': True,\n",
       "  'instructions': 'Make sure it is clean before recycling.',\n",
       "  'similar_items': ['Printed paper (Glossy and non-glossy)']},\n",
       " {'material': 'Paper',\n",
       "  'item': 'Writing paper',\n",
       "  'recyclable': True,\n",
       "  'instructions': 'Make sure it is clean before recycling.',\n",
       "  'similar_items': ['Writing paper']},\n",
       " {'material': 'Paper',\n",
       "  'item': 'Paper',\n",
       "  'recyclable': True,\n",
       "  'instructions': 'Make sure it is clean before recycling.',\n",
       "  'similar_items': ['Paper',\n",
       "   'Exam Papers',\n",
       "   'Notes',\n",
       "   'Notebook',\n",
       "   'Mail',\n",
       "   'Letter',\n",
       "   'Bill',\n",
       "   'Foolscap Paper',\n",
       "   'Exercise Book']},\n",
       " {'material': 'Others',\n",
       "  'item': 'Clothes',\n",
       "  'recyclable': False,\n",
       "  'instructions': \"Clothes should be donated if they are in good condition. <br/><br/> Click <a href='https://www.nea.gov.sg/our-services/waste-management/donation-resale-and-repair-channels/' target='_blank' style='color:black; font-weight:600; text-decoration: underline; font-style: italic;'>here</a> for avenues to donate, resell or repair your clothes.\",\n",
       "  'similar_items': ['T-Shirt',\n",
       "   'Shorts',\n",
       "   'Pants',\n",
       "   'Skirt',\n",
       "   'Jacket',\n",
       "   'Shirts',\n",
       "   'Tie',\n",
       "   'Blouse',\n",
       "   'Singlet',\n",
       "   'Camisole',\n",
       "   'Clothes']},\n",
       " {'material': 'Paper',\n",
       "  'item': 'Newspaper',\n",
       "  'recyclable': True,\n",
       "  'instructions': 'Make sure it is clean before recycling.',\n",
       "  'similar_items': ['Newspaper']}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read from data.json\n",
    "import json\n",
    "items = []\n",
    "with open('data.json', 'r') as file:\n",
    "    items = json.load(file)\n",
    "\n",
    "print(len(items))\n",
    "items[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_items = set([item['item'] for item in items])\n",
    "len(unique_items)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printed paper (Glossy and non-glossy) 2\n",
      "Writing paper 2\n",
      "Flyer (Glossy and non-glossy) 2\n",
      "Magazine (Glossy and non-glossy) 2\n",
      "Telephone directory 2\n",
      "Envelope (With and without plastic window) 2\n",
      "Plastic envelope 2\n",
      "Red packet 2\n",
      "Namecard 2\n",
      "Greeting card 2\n",
      "Shredded paper 2\n",
      "Carton box 2\n",
      "Cardboard box 2\n",
      "Printed paper box 2\n",
      "Plastic bottle 2\n",
      "Plastic container 2\n",
      "Soft drink bottle 2\n",
      "Carbonated drink bottle 2\n",
      "Medicine bottle 2\n",
      "Fruit box 2\n",
      "Ziplock bag 2\n",
      "Plastic packaging 2\n",
      "Plastic disposables 2\n",
      "Plastic crockery 2\n",
      "Plastic packaging with foil 2\n",
      "Potato chip bags 2\n",
      "Expired credit cards 2\n",
      "Plastic packaging contaminated with food/oil stains 2\n",
      "Glass bottle 2\n",
      "Wine bottle 2\n",
      "Liquor bottle 2\n",
      "Food glass bottle 2\n",
      "Sauce bottle 2\n",
      "Condiment bottle 2\n",
      "Jam spread bottle 2\n",
      "Food jars 2\n",
      "Cosmetic glass bottle 2\n",
      "Perfume glass bottle 2\n",
      "Drinking glass 2\n",
      "Paint container 2\n",
      "Paint cans 2\n",
      "Laptop 3\n",
      "Household battery 2\n",
      "Food waste 2\n",
      "Stationery 2\n",
      "Furniture 2\n",
      "Sports shoes 2\n",
      "School shoes 2\n",
      "Tablet computer 2\n",
      "Mobile phone 2\n"
     ]
    }
   ],
   "source": [
    "item_count = {}\n",
    "for item in items:\n",
    "    if item['item'] in item_count:\n",
    "        item_count[item['item']] += 1\n",
    "    else:\n",
    "        item_count[item['item']] = 1\n",
    "\n",
    "# print the items with count > 1\n",
    "for item, count in item_count.items():\n",
    "    if count > 1:\n",
    "        print(item, count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting similar items into item names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n"
     ]
    }
   ],
   "source": [
    "# read from data.json\n",
    "import json\n",
    "items = []\n",
    "with open('data.json', 'r') as file:\n",
    "    items = json.load(file)\n",
    "\n",
    "print(len(items))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_items = list(set([item['item'] for item in items]))\n",
    "len(all_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Medicine glass bottle',\n",
       " 'Computer battery',\n",
       " 'Power-assisted bicycle',\n",
       " 'Calendar',\n",
       " 'Umbrella']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in items:\n",
    "    all_items.extend(item['similar_items'])\n",
    "print(len(all_items))\n",
    "all_items[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['', '100 Plus', '100 plus', '9-Volt battery', 'ADAT']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean to trim any leading and trailing space, remove any duplicates, sort a to z\n",
    "all_items = list(set([item.strip() for item in all_items]))\n",
    "all_items = sorted(all_items)\n",
    "print(len(all_items))\n",
    "all_items[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_items = all_items[1:]\n",
    "len(all_items)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to csv\n",
    "import csv\n",
    "with open('all_items.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['item'])\n",
    "    writer.writerows([[item] for item in all_items])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output to json\n",
    "with open('all_items.json', 'w') as file:\n",
    "    json.dump(all_items, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "vision_model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base64 encode an image\n",
    "import base64\n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"Getting the base64 string\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "img_base64 = encode_image(\n",
    "    \"../images/rubc_cube.jpg\"\n",
    ")\n",
    "# Write the base64 string to a text file\n",
    "with open(\"encoded_image.txt\", \"w\") as file:\n",
    "    file.write(img_base64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "from enum import Enum\n",
    "\n",
    "class Items(BaseModel):\n",
    "    items: List[str] = Field(description=\"List of item names\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding similar items\n",
    "NEA_ITEM_NAMES = [\n",
    "    \"9-Volt battery\",\n",
    "    \"Aerosol cans\",\n",
    "    \"Air Conditioner\",\n",
    "    \"Alkaline battery\",\n",
    "    \"Audio sound system\",\n",
    "    \"Bag\",\n",
    "    \"Glass Bakeware\",\n",
    "    \"Battery charger\",\n",
    "    \"Bedsheet\",\n",
    "    \"Glass beer bottle\",\n",
    "    \"Beer can\",\n",
    "    \"Beverage carton\",\n",
    "    \"Beverage glass bottle\",\n",
    "    \"Beverage metal can\",\n",
    "    \"Bio-degradable bag\",\n",
    "    \"Biscuit tin\",\n",
    "    \"Blanket\",\n",
    "    \"Blister pack\",\n",
    "    \"Plastic bodywash bottle\",\n",
    "    \"Books\",\n",
    "    \"Borosilicate glassware\",\n",
    "    \"Bread bag\",\n",
    "    \"Briefcase\",\n",
    "    \"Brochure (Glossy and non-glossy)\",\n",
    "    \"Bubble tea cups\",\n",
    "    \"Bubble wrap\",\n",
    "    \"Bulky waste\",\n",
    "    \"Button cell battery\",\n",
    "    \"CD\",\n",
    "    \"CD casing\",\n",
    "    \"CD player\",\n",
    "    \"Calendar\",\n",
    "    \"Canned food\",\n",
    "    \"Carbonated drink bottle\",\n",
    "    \"Carbonated drink can\",\n",
    "    \"Cardboard box\",\n",
    "    \"Carton box\",\n",
    "    \"Cassette\",\n",
    "    \"Ceramic plate\",\n",
    "    \"Ceramic products\",\n",
    "    \"Chairs\",\n",
    "    \"Child seat\",\n",
    "    \"Cigarettes\",\n",
    "    \"Clean aluminium foil\",\n",
    "    \"Clean aluminium tray\",\n",
    "    \"Cling film\",\n",
    "    \"Clothes\",\n",
    "    \"Coffee capsules\",\n",
    "    \"Computer battery\",\n",
    "    \"Computer mouse\",\n",
    "    \"Glass condiment bottle\",\n",
    "    \"Cooking pot\",\n",
    "    \"Cosmetic glass bottle\",\n",
    "    \"Cotton bud\",\n",
    "    \"Cotton wool\",\n",
    "    \"Crayon drawing\",\n",
    "    \"Crystal glass\",\n",
    "    \"Curtains\",\n",
    "    \"DVD\",\n",
    "    \"DVD casing\",\n",
    "    \"DVD player\",\n",
    "    \"Desktop computer\",\n",
    "    \"Desktop monitor\",\n",
    "    \"Detergent bottle\",\n",
    "    \"Diaper\",\n",
    "    \"Dirty aluminium foil\",\n",
    "    \"Dirty aluminium tray\",\n",
    "    \"Disposable shaver\",\n",
    "    \"Disposable wooden chopsticks\",\n",
    "    \"Docking station\",\n",
    "    \"Drink packet\",\n",
    "    \"Drinking glass\",\n",
    "    \"Drinking straw\",\n",
    "    \"Hairdryer\",\n",
    "    \"E-scooter\",\n",
    "    \"Electric bicycle\",\n",
    "    \"Electric fan\",\n",
    "    \"Electric kettle\",\n",
    "    \"Electric mobility devices\",\n",
    "    \"Electric mobility scooter\",\n",
    "    \"Electric scooter\",\n",
    "    \"Electric shaver\",\n",
    "    \"Electronic cables\",\n",
    "    \"Electronic waste\",\n",
    "    \"Envelope (With and without plastic window)\",\n",
    "    \"Expired credit cards\",\n",
    "    \"Facial cleanser bottle\",\n",
    "    \"Fluorescent bulb\",\n",
    "    \"Fluorescent lamp\",\n",
    "    \"Flyer (Glossy and non-glossy)\",\n",
    "    \"Food blender\",\n",
    "    \"Food glass bottle\",\n",
    "    \"Food jars\",\n",
    "    \"Food metal can\",\n",
    "    \"Food processor\",\n",
    "    \"Food tin\",\n",
    "    \"Food waste\",\n",
    "    \"Football shoes (without metal studs)\",\n",
    "    \"Fridge\",\n",
    "    \"Fruit box\",\n",
    "    \"Furniture\",\n",
    "    \"Gaming console\",\n",
    "    \"Gift wrapping paper\",\n",
    "    \"Glad wrap\",\n",
    "    \"Glass bottle\",\n",
    "    \"Glass cup\",\n",
    "    \"Glass plate\",\n",
    "    \"Glass with metal wires\",\n",
    "    \"Glassware\",\n",
    "    \"Glitter paper\",\n",
    "    \"Greeting card\",\n",
    "    \"Hard disk drive\",\n",
    "    \"Horticultural waste\",\n",
    "    \"Household battery\",\n",
    "    \"Incandescent bulb\",\n",
    "    \"Incandescent lamp\",\n",
    "    \"Jam spread bottle\",\n",
    "    \"Joss sticks\",\n",
    "    \"Juice packet\",\n",
    "    \"Keyboard\",\n",
    "    \"LED bulb\",\n",
    "    \"LED lamp\",\n",
    "    \"Lamp\",\n",
    "    \"Lamp fixture\",\n",
    "    \"Lamp stand\",\n",
    "    \"Laptop\",\n",
    "    \"Large household appliances\",\n",
    "    \"Leftover medicine\",\n",
    "    \"Light bulb\",\n",
    "    \"Liquor bottle\",\n",
    "    \"Luggage bag\",\n",
    "    \"Magazine (Glossy and non-glossy)\",\n",
    "    \"Magazine wrapper\",\n",
    "    \"Masks\",\n",
    "    \"Medals\",\n",
    "    \"Medicine bottle\",\n",
    "    \"Medicine glass bottle\",\n",
    "    \"Melamine cups\",\n",
    "    \"Melamine plates\",\n",
    "    \"Melamine products\",\n",
    "    \"Metal accessories\",\n",
    "    \"Metal bottle cap\",\n",
    "    \"Metal container\",\n",
    "    \"Metal cutlery\",\n",
    "    \"Microwave oven\",\n",
    "    \"Milk bottles\",\n",
    "    \"Milk carton\",\n",
    "    \"Mineral water bottle\",\n",
    "    \"Mirror\",\n",
    "    \"Mobile phone\",\n",
    "    \"Mobile phone battery\",\n",
    "    \"Modem\",\n",
    "    \"Mouthwash bottle\",\n",
    "    \"Music player\",\n",
    "    \"Namecard\",\n",
    "    \"Newsletter\",\n",
    "    \"Newspaper\",\n",
    "    \"Non-food metal container\",\n",
    "    \"Oven-safe food containers\",\n",
    "    \"Oxo-degradable bag\",\n",
    "    \"Paint cans\",\n",
    "    \"Metal paint container\",\n",
    "    \"Paper\",\n",
    "    \"Paper Packaging (printed paper box etc)\",\n",
    "    \"Paper bag\",\n",
    "    \"Paper box\",\n",
    "    \"Paper cup\",\n",
    "    \"Paper disposables\",\n",
    "    \"Paper egg trays\",\n",
    "    \"Paper packaging contaminated with food\",\n",
    "    \"Paper packaging with food\",\n",
    "    \"Paper plate\",\n",
    "    \"Paper receipt\",\n",
    "    \"Paper towel\",\n",
    "    \"Paper towel tube\",\n",
    "    \"Pen\",\n",
    "    \"Pencil\",\n",
    "    \"Perfume glass bottle\",\n",
    "    \"Personal mobility devices\",\n",
    "    \"Pizza boxes\",\n",
    "    \"Plant waste\",\n",
    "    \"Plastic bag\",\n",
    "    \"Plastic bottle\",\n",
    "    \"Plastic bottle cap\",\n",
    "    \"Plastic clothes hanger\",\n",
    "    \"Plastic container\",\n",
    "    \"Plastic crockery\",\n",
    "    \"Plastic cups\",\n",
    "    \"Plastic cutlery\",\n",
    "    \"Plastic disposables\",\n",
    "    \"Plastic egg trays\",\n",
    "    \"Plastic envelope\",\n",
    "    \"Plastic film\",\n",
    "    \"Plastic food wrap\",\n",
    "    \"Plastic packaging\",\n",
    "    \"Plastic packaging contaminated with food/oil stains\",\n",
    "    \"Plastic packaging for packet drink\",\n",
    "    \"Plastic packaging with foil\",\n",
    "    \"Plastic takeaway food container\",\n",
    "    \"Polystyrene foam product\",\n",
    "    \"Porcelain\",\n",
    "    \"Portable charger\",\n",
    "    \"Potato chip bags\",\n",
    "    \"Power bank\",\n",
    "    \"Power-assisted bicycle\",\n",
    "    \"Printed paper (Glossy and non-glossy)\",\n",
    "    \"Printed paper box\",\n",
    "    \"Printer\",\n",
    "    \"Pyrex glassware\",\n",
    "    \"Radio\",\n",
    "    \"Rechargeable battery\",\n",
    "    \"Red packet\",\n",
    "    \"Refrigerator\",\n",
    "    \"Ribbons\",\n",
    "    \"Rice cooker\",\n",
    "    \"Router\",\n",
    "    \"Rusty metal cans\",\n",
    "    \"Sanitary pad\",\n",
    "    \"Saran wrap\",\n",
    "    \"Sauce bottle\",\n",
    "    \"School shoes\",\n",
    "    \"Shampoo\",\n",
    "    \"Shampoo bottle\",\n",
    "    \"Shoes\",\n",
    "    \"Shredded paper\",\n",
    "    \"Soap bottle\",\n",
    "    \"Soft drink bottle\",\n",
    "    \"Soft drink can\",\n",
    "    \"Speaker\",\n",
    "    \"Spectacles\",\n",
    "    \"Sports shoes\",\n",
    "    \"Spray cans\",\n",
    "    \"Standing fan\",\n",
    "    \"Stationery\",\n",
    "    \"Steel wool\",\n",
    "    \"Styrofoam\",\n",
    "    \"Styrofoam clamshell container\",\n",
    "    \"Styrofoam cup\",\n",
    "    \"Supplement glass bottle\",\n",
    "    \"TV\",\n",
    "    \"Table\",\n",
    "    \"Tablet computer\",\n",
    "    \"Tea pot\",\n",
    "    \"Telephone directory\",\n",
    "    \"Television\",\n",
    "    \"Tempered glass\",\n",
    "    \"Textbooks\",\n",
    "    \"Textile\",\n",
    "    \"Tissue box\",\n",
    "    \"Tissue box packaging\",\n",
    "    \"Tissue paper\",\n",
    "    \"Toaster oven\",\n",
    "    \"Toilet paper\",\n",
    "    \"Toilet paper packaging\",\n",
    "    \"Toilet roll tube\",\n",
    "    \"Toys\",\n",
    "    \"Glass tube\",\n",
    "    \"Umbrella\",\n",
    "    \"Vacuum cleaner\",\n",
    "    \"Vase\",\n",
    "    \"Video tape\",\n",
    "    \"Washing machine\",\n",
    "    \"Water bottle\",\n",
    "    \"Wax paper\",\n",
    "    \"Wet wipes\",\n",
    "    \"Windows\",\n",
    "    \"Wine bottle\",\n",
    "    \"Wine glass\",\n",
    "    \"Wooden chopsticks\",\n",
    "    \"Writing paper\",\n",
    "    \"Ziplock bag\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# including similar items\n",
    "NEA_ITEM_NAMES = [\n",
    "    \"100 Plus\", \"100 plus\", \"9-Volt battery\", \"ADAT\", \"ASUS\", \"ATM Card\", \"Absolut\", \"Acer\", \"Adidas\", \"Aerosol cans\", \"Air Conditioner\", \"Alkaline battery\", \"Almon Buuter\", \"Anchor\", \"Android\", \"Ang Pow\", \"Anniversary Card\", \"Apple\", \"Apple Juice\", \"Aqua\", \"Asahi\", \"Asics\", \"Assessment Books\", \"Audio sound system\", \"Bag\", \"Bakeware\", \"Baking Paper\", \"Bank Card\", \"Battery charger\", \"Bed Frame\", \"Bedsheet\", \"Beer bottle\", \"Beer can\", \"Belvedere\", \"BenjaminmooreYeo's\", \"Berocca\", \"Beverage carton\", \"Beverage glass bottle\", \"Beverage metal can\", \"Bill\", \"Bio-degradable bag\", \"Birthday Card\", \"Biscuit tin\", \"Blackmores\", \"Blanket\", \"Blister pack\", \"Blouse\", \"Bodywash bottle\", \"Bombay Sapphire\", \"Bonjour\", \"Books\", \"Borosilicate glassware\", \"Bowl\", \"Bread bag\", \"Breda\", \"Briefcase\", \"Brochure (Glossy and non-glossy)\", \"Bubble tea cups\", \"Bubble wrap\", \"Bulky waste\", \"Business Card\", \"Button cell battery\", \"CD\", \"CD Casing\", \"CD casing\", \"CD player\", \"Calbee\", \"Calendar\", \"Calsberg\", \"Camisole\", \"Canned food\", \"Carbonated drink bottle\", \"Carbonated drink can\", \"Cardboard box\", \"Carton box\", \"Cassette\", \"Cellphone\", \"Ceramic plate\", \"Ceramic products\", \"Cereal box\", \"Chair\", \"Chairs\", \"Champagne\", \"Child seat\", \"Chilli\", \"Chilli Sauce Bottle\", \"Chivas\", \"Christmas Card\", \"Cigarettes\", \"Clean aluminium foil\", \"Clean aluminium tray\", \"Cling film\", \"Clothes\", \"Coffee Table\", \"Coffee capsules\", \"Coke\", \"Comic books\", \"Compact Disc\", \"Computer battery\", \"Computer mouse\", \"Condiment bottle\", \"Containers\", \"Cooking pot\", \"Corona\", \"Correction liquid\", \"Correction tape\", \"Cosmetic glass bottle\", \"Cotton Bud\", \"Cotton Wool\", \"Cotton bud\", \"Cotton wool\", \"Couch\", \"Crayon drawing\", \"Crocs\", \"Crystal glass\", \"Curtains\", \"DVD\", \"DVD casing\", \"DVD player\", \"Dasani\", \"Debit Card\", \"Dell\", \"Desktop computer\", \"Desktop monitor\", \"Detergent bottle\", \"Diaper\", \"Diary\", \"Dirty aluminium foil\", \"Dirty aluminium tray\", \"Disposable Knife\", \"Disposable bowl\", \"Disposable cup\", \"Disposable cutlery\", \"Disposable fork\", \"Disposable plate\", \"Disposable shaver\", \"Disposable spoon\", \"Disposable wooden chopsticks\", \"Docking station\", \"Dress shoes\", \"Drink packet\", \"Drinking glass\", \"Drinking straw\", \"Dryer\", \"Duracell\", \"E-scooter\", \"Electric bicycle\", \"Electric fan\", \"Electric kettle\", \"Electric mobility devices\", \"Electric mobility scooter\", \"Electric scooter\", \"Electric shaver\", \"Electronic cables\", \"Electronic waste\", \"Energizer\", \"Enriched\", \"Envelope (With and without plastic window)\", \"Eveready\", \"Evian\", \"Exam Papers\", \"Exercise Book\", \"Exercise book\", \"Expired credit cards\", \"F&N\", \"FNN\", \"Fabric\", \"Facial cleanser bottle\", \"Fan\", \"Fanta\", \"Farm Fresh\", \"Fiji\", \"Fire-Wire\", \"Fluorescent bulb\", \"Fluorescent lamp\", \"Flyer (Glossy and non-glossy)\", \"Food blender\", \"Food glass bottle\", \"Food jars\", \"Food metal can\", \"Food processor\", \"Food tin\", \"Food waste\", \"Foolscap Paper\", \"Football shoes (without metal studs)\", \"Fork\", \"Fridge\", \"Fruit Container\", \"Fruit Juice Packet\", \"Fruit box\", \"Furniture\", \"Gaming console\", \"Gardenia\", \"Gift\", \"Gift bag\", \"Gift wrapping paper\", \"Gifts\", \"Gin\", \"Glad wrap\", \"Glass Bakeware\", \"Glass Tube\", \"Glass bottle\", \"Glass cup\", \"Glass plate\", \"Glass with metal wires\", \"Glasses\", \"Glassware\", \"Glitter paper\", \"Google Phone\", \"Graph paper\", \"Green Tea\", \"Green packet\", \"Greenfield\", \"Greeting card\", \"Grey Goose\", \"Guinness\", \"HDMI Cable\", \"HL\", \"HP\", \"Hammerite\", \"Handphone\", \"Hard disk drive\", \"Heaven & Earth\", \"Heels\", \"Heineken\", \"Hendricks\", \"Highlighter\", \"Hoegarden\", \"Hojicha Tea\", \"Honey\", \"Hong Bao\", \"Horticultural waste\", \"Household battery\", \"IMac\", \"IPad\", \"Ice Lemon Tea\", \"Ice Mountain\", \"Incandescent bulb\", \"Incandescent lamp\", \"Ipad\", \"Iphone\", \"Jack Daniels\", \"Jacket\", \"Jagermeister\", \"Jam spread bottle\", \"Johnny Walker\", \"Joss sticks\", \"Jotter book\", \"Jotun\", \"Journal\", \"Juice\", \"Juice packet\", \"Ketchup\", \"Ketchup Bottle\", \"Keyboard\", \"Kingfisher\", \"Kitchen Roll\", \"Kitchen Towel\", \"Knife\", \"Kronenbourgh\", \"LED bulb\", \"LED lamp\", \"Lamp\", \"Lamp fixture\", \"Lamp stand\", \"Laptop\", \"Large household appliances\", \"Lay's\", \"Leaflet\", \"Leftover medicine\", \"Lenovo\", \"Letter\", \"Light bulb\", \"Lightning cable\", \"Liquor bottle\", \"Luggage bag\", \"Lychee Tea\", \"Macbook\", \"Macbook Air\", \"Macbook Pro\", \"Magazine (Glossy and non-glossy)\", \"Magazine wrapper\", \"Mail\", \"Make up\", \"Marigold\", \"Masks\", \"Mattress\", \"Mayonaise\", \"Meadows\", \"Medals\", \"Medicine Pack\", \"Medicine bottle\", \"Medicine glass bottle\", \"Meiji\", \"Melamine cups\", \"Melamine plates\", \"Melamine products\", \"Metal accessories\", \"Metal bottle cap\", \"Metal container\", \"Metal cutlery\", \"Microwave oven\", \"Milk bottles\", \"Milk carton\", \"Milo\", \"Mineral water bottle\", \"Mirror\", \"Mobile phone\", \"Mobile phone battery\", \"Modem\", \"Monkey Shoulder\", \"Mouth wash\", \"Mouthwash bottle\", \"Music player\", \"Mustard\", \"Namecard\", \"Nescafe\", \"Nespresso\", \"New Balance\", \"Newsletter\", \"Newspaper\", \"Nike\", \"Nippon Paint\", \"Nokia\", \"Non-food metal container\", \"Notebook\", \"Notes\", \"Notice\", \"Novel\", \"Oatly\", \"Oatside\", \"Oolong Tea\", \"Orange Juice\", \"Oven-safe food containers\", \"Oxo-degradable bag\", \"Packaging\", \"Paint cans\", \"Paint container\", \"Pampers\", \"Pamphlet\", \"Pants\", \"Paper\", \"Paper Packaging (printed paper box etc)\", \"Paper bag\", \"Paper box\", \"Paper cup\", \"Paper disposables\", \"Paper egg trays\", \"Paper packaging contaminated with food\", \"Paper packaging with food\", \"Paper plate\", \"Paper receipt\", \"Paper towel\", \"Paper towel tube\", \"Parchment Paper\", \"Peanut Butter\", \"Peel Fresh\", \"Pen\", \"Pencil\", \"Pepsi\", \"Perfume glass bottle\", \"Personal mobility devices\", \"Pill Bottle\", \"Pizza Box\", \"Pizza boxes\", \"Plant waste\", \"Plaster\", \"Plastic Cup Lids\", \"Plastic Fork\", \"Plastic Knife\", \"Plastic bag\", \"Plastic bottle\", \"Plastic bottle cap\", \"Plastic bowl\", \"Plastic clothes hanger\", \"Plastic container\", \"Plastic crockery\", \"Plastic cups\", \"Plastic cutlery\", \"Plastic disposables\", \"Plastic egg trays\", \"Plastic envelope\", \"Plastic film\", \"Plastic food wrap\", \"Plastic packaging\", \"Plastic packaging contaminated with food/oil stains\", \"Plastic packaging for packet drink\", \"Plastic packaging with foil\", \"Plastic plate\", \"Plastic takeaway food container\", \"Plate\", \"Pokka\", \"Polystyrene foam product\", \"Porcelain\", \"Portable charger\", \"Post-it\", \"Potato chip bags\", \"Power bank\", \"Power-assisted bicycle\", \"Present\", \"Presents\", \"Printed paper (Glossy and non-glossy)\", \"Printed paper box\", \"Printer\", \"Prosecco\", \"Publication\", \"Puma\", \"Pumps\", \"Pyrex glassware\", \"Radio\", \"Rafflespaint\", \"Razer\", \"Razor\", \"Rechargeable battery\", \"Red Wine\", \"Red packet\", \"Redoxon\", \"Reebok\", \"Refrigerator\", \"Ribbons\", \"Ribena\", \"Rice cooker\", \"Roku Gin\", \"Ronseal\", \"Router\", \"Ruffles\", \"Ruler\", \"Rum\", \"Rusty metal cans\", \"Samsung\", \"Sandles\", \"Sanitary pad\", \"Saran wrap\", \"Sauce bottle\", \"Saucer\", \"School Diary\", \"School shoes\", \"Scotts\", \"Seal bag\", \"Seasons\", \"Serving Bowl\", \"Serving Plate\", \"Sesame oil\", \"Shampoo\", \"Shampoo bottle\", \"Shirts\", \"Shoes\", \"Shorts\", \"Shredded paper\", \"Singlet\", \"Sketchers\", \"Skirt\", \"Smartwater\", \"Smirnoff\", \"Sneakers\", \"Soap bottle\", \"Soda cans\", \"Sofa\", \"Soft drink bottle\", \"Soft drink can\", \"Soy Sauce\", \"Speaker\", \"Spectacles\", \"Spoon\", \"Spork\", \"Sports shoes\", \"Spray cans\", \"Spread\", \"Sprite\", \"Stamps\", \"Standing fan\", \"Stationery\", \"Steel wool\", \"Storybook\", \"Styrofoam\", \"Styrofoam clamshell container\", \"Styrofoam cup\", \"Sunkist\", \"Sunshine\", \"Super Value\", \"Supplement glass bottle\", \"T-Shirt\", \"TRS\", \"TS\", \"TV\", \"Table\", \"Tablet computer\", \"Takeaway\", \"Tanquery\", \"Tea pot\", \"Telephone directory\", \"Television\", \"Tempered glass\", \"Ten Year Series\", \"Tequila\", \"Textbooks\", \"Textile\", \"The Botanist\", \"Tie\", \"Tiger\", \"Tiger Brand\", \"Tissue box\", \"Tissue box packaging\", \"Tissue paper\", \"Toaster oven\", \"Toilet paper\", \"Toilet paper packaging\", \"Toilet roll tube\", \"Toiletries\", \"Top One\", \"Torres\", \"Toys\", \"Tube\", \"Tupperware\", \"Twisties\", \"Type B\", \"Type C\", \"Tyrrell's\", \"USB\", \"USB C\", \"Umbrella\", \"Under Armour\", \"Vacuum cleaner\", \"Vase\", \"Video tape\", \"Vitasoy\", \"Volvic\", \"Washing machine\", \"Water bottle\", \"Wax paper\", \"Wet Wipes\", \"Wet wipes\", \"Whisky\", \"White Wine\", \"Windows\", \"Wine bottle\", \"Wine glass\", \"Wooden chopsticks\", \"Wrapper\", \"Writing paper\", \"XLR\", \"Yeo's\", \"Ziplock bag\", \"basketball\", \"biscuits\", \"boots\", \"cabinet\", \"candy\", \"chocolate\", \"cookies\", \"crackers\", \"cupboard\", \"cushion\", \"dining table\", \"drumstick\", \"eraser\", \"fish\", \"food peels\", \"football\", \"fragrance\", \"golf ball\", \"gummy bears\", \"hua tiao jiu\", \"iron\", \"ironing board\", \"leftovers\", \"marker\", \"mason jar\", \"meat\", \"nintendo\", \"noodles\", \"pH Balancer\", \"permanent Marker\", \"pizza\", \"plastic bag\", \"plastic bubble tea carrier\", \"playstation\", \"rice\", \"robot cleaner\", \"robot vacuum\", \"roller blades\", \"roller skates\", \"rotten food\", \"seafood\", \"shoe rack\", \"shot glass\", \"spoiled food\", \"stool\", \"sweets\", \"switch\", \"tennis ball\", \"vegetables\", \"whiteboard marker\", \"whskey glass\", \"wii\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NEA_ITEM_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../images/test/batch3/Newsletter (4).jpeg',\n",
       " '../images/test/batch3/Textbooks (3).jpg',\n",
       " '../images/test/batch3/Disposable spoon (3).jpg',\n",
       " '../images/test/batch3/Computer mouse (2).jpg',\n",
       " '../images/test/batch3/bodywash bottle (3).jpeg']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "IMAGE_DIR = '../images/test/batch3'\n",
    "filenames = [file for file in os.listdir(IMAGE_DIR) if file.endswith('jpeg') or file.endswith('jpg') or file.endswith('webp')]\n",
    "filenames = [os.path.join(IMAGE_DIR, filename) for filename in filenames]\n",
    "print(f\"Number of images: {len(filenames)}\")\n",
    "filenames[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "from PIL import Image\n",
    "\n",
    "def calculate_openai_image_tokens(image_filepath: str):\n",
    "    image = Image.open(image_filepath)\n",
    "    width, height = image.size\n",
    "\n",
    "    if width > 2048 or height > 2048:\n",
    "        aspect_ratio = width / height\n",
    "        if aspect_ratio > 1:\n",
    "            width, height = 2048, int(2048 / aspect_ratio)\n",
    "        else:\n",
    "            width, height = int(2048 * aspect_ratio), 2048\n",
    "            \n",
    "    if width >= height and height > 768:\n",
    "        width, height = int((768 / height) * width), 768\n",
    "    elif height > width and width > 768:\n",
    "        width, height = 768, int((768 / width) * height)\n",
    "\n",
    "    tiles_width = ceil(width / 512)\n",
    "    tiles_height = ceil(height / 512)\n",
    "    total_tokens = 85 + 170 * (tiles_width * tiles_height)\n",
    "    \n",
    "    return total_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "image_prompt = \"\"\"\n",
    "I have an image containing items that I am unsure of whether they are recyclable. Please help me to identify the item(s) in the image.\n",
    "Return the best or closest matching item(s) you have identified to the following NEA_ITEM_NAMES: {NEA_ITEM_NAMES}\n",
    "\n",
    "If there are best or closest matching item(s), you must return the item name according to the NEA_ITEM_NAMES.\n",
    "Return the item as \"Other\" if the item is not in the list of NEA_ITEM_NAMES.\n",
    "\n",
    "Return the answer as JSON output according to the following schema:\n",
    "{{\n",
    "    \"items\": ['item1', 'item2', ...]\n",
    "}}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "image_prompt = image_prompt.format(NEA_ITEM_NAMES=NEA_ITEM_NAMES)\n",
    "\n",
    "system_message = \"You are an expert on answering questions briefly and accurately about recycling in Singapore. Your name is Bloo. Users may send you images of items to check if the items can be recycled, and your task is to correctly identify what are the items in the image.\"\n",
    "\n",
    "image_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_message,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            [\n",
    "                {\"type\": \"text\", \"text\": \"{image_prompt}\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"data:image/jpeg;base64,{img_base64}\"},\n",
    "                },\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "vision_model_json_output = vision_model.with_structured_output(schema=Items)\n",
    "\n",
    "chain_text_stream = image_prompt_template | vision_model_json_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      System message token count: 52\n",
      "      Image prompt token count: 2780\n",
      "      Total prompt token count: 2832\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_name_for_model('gpt-4o')\n",
    "\n",
    "image_prompt_tokens_count = num_tokens_from_string(image_prompt, encoding)\n",
    "system_message_tokens_count = num_tokens_from_string(system_message, encoding)\n",
    "print(f\"\"\"\n",
    "      System message token count: {system_message_tokens_count}\n",
    "      Image prompt token count: {image_prompt_tokens_count}\n",
    "      Total prompt token count: {image_prompt_tokens_count + system_message_tokens_count}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import random\n",
    "import time\n",
    "import openai\n",
    "\n",
    "# define a retry decorator\n",
    "def retry_after_delay(\n",
    "    func,\n",
    "    errors: tuple = (openai.RateLimitError,),\n",
    "):\n",
    "\n",
    "    def wrapper(*args, delay: float = 65, max_retries: int = 3, **kwargs):\n",
    "        # Initialize variables\n",
    "        num_retries = 0\n",
    "\n",
    "        # Loop until a successful response or max_retries is hit or an exception is raised\n",
    "        while True:\n",
    "            try:\n",
    "                return func(*args, **kwargs)\n",
    "\n",
    "            # Retry on specified errors\n",
    "            except errors as e:\n",
    "                print(e, end='\\n\\n')\n",
    "                # Increment retries\n",
    "                num_retries += 1\n",
    "\n",
    "                # Check if max retries has been reached\n",
    "                if num_retries > max_retries:\n",
    "                    raise Exception(\n",
    "                        f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
    "                    )\n",
    "\n",
    "                # Sleep for the delay\n",
    "                time.sleep(delay)\n",
    "\n",
    "            # Raise exceptions for any errors not specified\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@retry_after_delay\n",
    "def batch_image_prediction_with_retry(filenames, **kwargs):\n",
    "    batch_res = chain_text_stream.batch([{'image_prompt': image_prompt, 'img_base64': encode_image(filename)} for filename in filenames]) # batch_res is List[Items]\n",
    "\n",
    "    return batch_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint save to csv\n",
    "import csv\n",
    "def save_to_csv(csv_filename: str, filenames: List[str], res: List[Items]):\n",
    "    file_exists = os.path.exists(csv_filename)\n",
    "    new_rows = [(filename, res.items) for filename, res in zip(filenames, res)]\n",
    "    with open(csv_filename, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            writer.writerow(['filename', 'predictions'])\n",
    "        writer.writerows(new_rows)\n",
    "\n",
    "    print(f'Saved {len(filenames)} rows to {csv_filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceeding 30000 TPM. Current tokens 32687\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Newsletter (4).jpeg,\n",
      "../images/test/batch3/Textbooks (3).jpg,\n",
      "../images/test/batch3/Disposable spoon (3).jpg,\n",
      "../images/test/batch3/Computer mouse (2).jpg,\n",
      "../images/test/batch3/bodywash bottle (3).jpeg,\n",
      "../images/test/batch3/Ribbons (2).jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32347\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/food blender (4).jpg,\n",
      "../images/test/batch3/Personal mobility devices.jpg,\n",
      "../images/test/batch3/blister pack (2).webp,\n",
      "../images/test/batch3/Vacuum cleaner.jpg,\n",
      "../images/test/batch3/Toaster oven.jpg,\n",
      "../images/test/batch3/Notebook (3).jpeg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32517\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Glass Tube.jpg,\n",
      "../images/test/batch3/Sanitary pad (4).jpg,\n",
      "../images/test/batch3/Lamp fixture.jpeg,\n",
      "../images/test/batch3/Cellphone (2).jpg,\n",
      "../images/test/batch3/shoes (2).jpg,\n",
      "../images/test/batch3/Rice cooker (4).jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 33027\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Disposable shaver (4).jpg,\n",
      "../images/test/batch3/Disposable spoon (2).jpg,\n",
      "../images/test/batch3/cd player (2).jpg,\n",
      "../images/test/batch3/Playstation (3).jpg,\n",
      "../images/test/batch3/Toaster oven (4).jpg,\n",
      "../images/test/batch3/wooden chopsticks.jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32687\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Steel wool.jpg,\n",
      "../images/test/batch3/Disposable shaver.jpg,\n",
      "../images/test/batch3/Audio sound system.jpg,\n",
      "../images/test/batch3/Battery charger.jpeg,\n",
      "../images/test/batch3/blister pack.jpg,\n",
      "../images/test/batch3/Aerosol cans (4).jpeg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32347\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Aerosol cans.jpg,\n",
      "../images/test/batch3/Textbooks.jpg,\n",
      "../images/test/batch3/Drinking glass (3).jpg,\n",
      "../images/test/batch3/Speaker (3).jpg,\n",
      "../images/test/batch3/Pyrex glassware (2).jpg,\n",
      "../images/test/batch3/Personal mobility devices (2).jpeg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32347\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Vase (2).jpg,\n",
      "../images/test/batch3/Battery charger (3).jpg,\n",
      "../images/test/batch3/cd player (3).jpg,\n",
      "../images/test/batch3/shoes (3).jpg,\n",
      "../images/test/batch3/Shampoo.jpg,\n",
      "../images/test/batch3/Football.jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32007\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Facial cleanser bottle (4).jpg,\n",
      "../images/test/batch3/Toys (2).jpg,\n",
      "../images/test/batch3/shoes.jpg,\n",
      "../images/test/batch3/food blender.jpg,\n",
      "../images/test/batch3/Football (5).jpg,\n",
      "../images/test/batch3/Spectacles (4).jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32687\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Speaker.jpg,\n",
      "../images/test/batch3/wooden chopsticks (3).jpg,\n",
      "../images/test/batch3/Calendar (2).jpg,\n",
      "../images/test/batch3/Rice cooker.jpg,\n",
      "../images/test/batch3/Drinking glass (2).jpeg,\n",
      "../images/test/batch3/Football (4).jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32347\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Ribbons (3).jpg,\n",
      "../images/test/batch3/Speaker (2).jpg,\n",
      "../images/test/batch3/Playstation.jpg,\n",
      "../images/test/batch3/Pyrex glassware (3).jpg,\n",
      "../images/test/batch3/Vase.jpg,\n",
      "../images/test/batch3/Toys.jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32347\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Steel wool (3).jpg,\n",
      "../images/test/batch3/Computer mouse (3).jpg,\n",
      "../images/test/batch3/Cooking pot (2).jpg,\n",
      "../images/test/batch3/Facial cleanser bottle (3).jpg,\n",
      "../images/test/batch3/Portable charger (3).jpg,\n",
      "../images/test/batch3/Textbooks (4).jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32687\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Toys (3).jpg,\n",
      "../images/test/batch3/Facial cleanser bottle (2).jpg,\n",
      "../images/test/batch3/Clean aluminium foil.jpg,\n",
      "../images/test/batch3/Vacuum cleaner (2).jpg,\n",
      "../images/test/batch3/Pyrex glassware.jpg,\n",
      "../images/test/batch3/Liquor bottle.jpeg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32177\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Television (2).jpg,\n",
      "../images/test/batch3/Diaper.jpg,\n",
      "../images/test/batch3/Textbooks (2).jpg,\n",
      "../images/test/batch3/Toaster oven (2).jpg,\n",
      "../images/test/batch3/cd player (4).jpg,\n",
      "../images/test/batch3/Rice cooker (2).jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32347\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Aerosol cans (2).jpg,\n",
      "../images/test/batch3/School shoes (2).jpg,\n",
      "../images/test/batch3/wet wipes.jpg,\n",
      "../images/test/batch3/bodywash bottle (2).jpg,\n",
      "../images/test/batch3/Cellphone.jpg,\n",
      "../images/test/batch3/Diaper (4).jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32347\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/School shoes (3).jpg,\n",
      "../images/test/batch3/food blender (3).jpg,\n",
      "../images/test/batch3/Cooking pot.jpg,\n",
      "../images/test/batch3/Television (3).jpg,\n",
      "../images/test/batch3/Lamp fixture (2).jpg,\n",
      "../images/test/batch3/wooden chopsticks (2).jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32347\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Facial cleanser bottle.jpg,\n",
      "../images/test/batch3/Sanitary pad (5).jpg,\n",
      "../images/test/batch3/Newsletter.jpg,\n",
      "../images/test/batch3/Diaper (2).jpg,\n",
      "../images/test/batch3/Joss sticks.jpg,\n",
      "../images/test/batch3/wet wipes (3).jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32687\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/jam spread bottle.jpg,\n",
      "../images/test/batch3/Personal mobility devices (3).jpg,\n",
      "../images/test/batch3/Newsletter (3).jpg,\n",
      "../images/test/batch3/Lamp fixture (4).jpg,\n",
      "../images/test/batch3/Ribbons.jpg,\n",
      "../images/test/batch3/Printer.jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32687\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Liquor bottle (4).jpeg,\n",
      "../images/test/batch3/Notebook.jpg,\n",
      "../images/test/batch3/jam spread bottle (2).jpg,\n",
      "../images/test/batch3/Spectacles (3).jpg,\n",
      "../images/test/batch3/Football (2).jpg,\n",
      "../images/test/batch3/Glass Tube (2).jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32347\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Disposable shaver (2).jpg,\n",
      "../images/test/batch3/Notebook (2).jpg,\n",
      "../images/test/batch3/Drinking glass.jpg,\n",
      "../images/test/batch3/cd player.jpeg,\n",
      "../images/test/batch3/bodywash bottle.jpg,\n",
      "../images/test/batch3/Sanitary pad (3).jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32347\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/9-Volt battery (2).jpg,\n",
      "../images/test/batch3/Playstation (2).jpg,\n",
      "../images/test/batch3/9-Volt battery.jpg,\n",
      "../images/test/batch3/Shampoo (2).jpg,\n",
      "../images/test/batch3/Newsletter (2).jpg,\n",
      "../images/test/batch3/Shampoo (3).jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32347\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Clean aluminium foil (2).jpg,\n",
      "../images/test/batch3/Liquor bottle (3).jpeg,\n",
      "../images/test/batch3/food blender (2).jpg,\n",
      "../images/test/batch3/School shoes.jpg,\n",
      "../images/test/batch3/Spectacles.jpg,\n",
      "../images/test/batch3/Aerosol cans (3).jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32687\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Football (3).jpg,\n",
      "../images/test/batch3/Lamp fixture (3).jpg,\n",
      "../images/test/batch3/Sanitary pad (2).jpg,\n",
      "../images/test/batch3/Spectacles (2).jpg,\n",
      "../images/test/batch3/Steel wool (2).jpg,\n",
      "../images/test/batch3/wet wipes (2).jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32177\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Cooking pot (3).jpeg,\n",
      "../images/test/batch3/Portable charger (2).jpg,\n",
      "../images/test/batch3/Audio sound system (3).jpg,\n",
      "../images/test/batch3/Battery Charger (2).jpg,\n",
      "../images/test/batch3/Toaster oven (3).jpg,\n",
      "../images/test/batch3/Joss sticks (3).jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32347\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Portable charger.jpg,\n",
      "../images/test/batch3/Disposable spoon.jpg,\n",
      "../images/test/batch3/Audio sound system (2).jpeg,\n",
      "../images/test/batch3/Printer (2).jpg,\n",
      "../images/test/batch3/Disposable shaver (3).jpg,\n",
      "../images/test/batch3/Calendar.jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Exceeding 30000 TPM. Current tokens 32687\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Liquor bottle (2).jpeg,\n",
      "../images/test/batch3/Computer mouse.jpg,\n",
      "../images/test/batch3/Spectacles (5).jpg,\n",
      "../images/test/batch3/Diaper (3).jpg,\n",
      "../images/test/batch3/jam spread bottle (3).jpg,\n",
      "../images/test/batch3/Rice cooker (3).jpg\n",
      "----------------------------\n",
      "Saved 6 rows to results_batch3_with_similar_items.csv\n",
      "Last file reached.\n",
      "batch invoking for filenames:\n",
      " ../images/test/batch3/Joss sticks (2).jpg,\n",
      "../images/test/batch3/Television.jpg,\n",
      "../images/test/batch3/Vase (3).jpg,\n",
      "../images/test/batch3/Shampoo (4).jpg\n",
      "----------------------------\n",
      "Saved 4 rows to results_batch3_with_similar_items.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Items(items=['Newsletter']),\n",
       " Items(items=['Books']),\n",
       " Items(items=['Disposable spoon']),\n",
       " Items(items=['Computer mouse']),\n",
       " Items(items=['Soap bottle', 'Shampoo bottle', 'Body lotion bottle']),\n",
       " Items(items=['Bedsheet']),\n",
       " Items(items=['Food blender']),\n",
       " Items(items=['Electric mobility scooter']),\n",
       " Items(items=['Blister pack']),\n",
       " Items(items=['robot cleaner']),\n",
       " Items(items=['Toaster oven']),\n",
       " Items(items=['Notebook']),\n",
       " Items(items=['Glass Tube']),\n",
       " Items(items=['Sanitary pad', 'Tampons']),\n",
       " Items(items=['Lamp', 'Lamp fixture', 'Lamp stand']),\n",
       " Items(items=['Iphone']),\n",
       " Items(items=['Shoes']),\n",
       " Items(items=['Rice cooker']),\n",
       " Items(items=['Disposable shaver']),\n",
       " Items(items=['Disposable spoon']),\n",
       " Items(items=['Audio sound system']),\n",
       " Items(items=['Gaming console']),\n",
       " Items(items=['Toaster oven']),\n",
       " Items(items=['Wooden chopsticks']),\n",
       " Items(items=['Steel wool']),\n",
       " Items(items=['Disposable shaver']),\n",
       " Items(items=['Audio sound system']),\n",
       " Items(items=['Battery charger', 'Electronic cables']),\n",
       " Items(items=['Blister pack']),\n",
       " Items(items=['Aerosol cans']),\n",
       " Items(items=['Aerosol cans']),\n",
       " Items(items=['Books']),\n",
       " Items(items=['Glass cup']),\n",
       " Items(items=['Audio sound system']),\n",
       " Items(items=['Bowl']),\n",
       " Items(items=['Electric mobility scooter']),\n",
       " Items(items=['Vase']),\n",
       " Items(items=['Battery charger', 'Electronic cables']),\n",
       " Items(items=['CD player']),\n",
       " Items(items=['Shoes']),\n",
       " Items(items=['Shampoo bottle']),\n",
       " Items(items=['football']),\n",
       " Items(items=['Facial cleanser bottle']),\n",
       " Items(items=['Toys']),\n",
       " Items(items=['New Balance']),\n",
       " Items(items=['Food processor']),\n",
       " Items(items=['basketball', 'football', 'tennis ball']),\n",
       " Items(items=['Glasses']),\n",
       " Items(items=['Audio sound system']),\n",
       " Items(items=['Wooden chopsticks']),\n",
       " Items(items=['Calendar']),\n",
       " Items(items=['Electric kettle', 'Rice cooker']),\n",
       " Items(items=['Glass cup']),\n",
       " Items(items=['football']),\n",
       " Items(items=['Ribbons']),\n",
       " Items(items=['Audio sound system']),\n",
       " Items(items=['Gaming console']),\n",
       " Items(items=['Glass Bakeware']),\n",
       " Items(items=['Vase']),\n",
       " Items(items=['Toys']),\n",
       " Items(items=['Steel wool', 'Plastic packaging']),\n",
       " Items(items=['Computer mouse']),\n",
       " Items(items=['Cooking pot']),\n",
       " Items(items=['Facial cleanser bottle']),\n",
       " Items(items=['ASUS', 'Portable charger']),\n",
       " Items(items=['Assessment Books']),\n",
       " Items(items=['Toys']),\n",
       " Items(items=['Facial cleanser bottle', 'Cosmetic glass bottle']),\n",
       " Items(items=['Aluminium foil']),\n",
       " Items(items=['Vacuum cleaner']),\n",
       " Items(items=['Glass Bakeware']),\n",
       " Items(items=['Chivas', 'Gin']),\n",
       " Items(items=['TV', 'Clock', 'Soundbar']),\n",
       " Items(items=['Diaper']),\n",
       " Items(items=['Books']),\n",
       " Items(items=['Toaster oven']),\n",
       " Items(items=['Audio sound system']),\n",
       " Items(items=['Rice cooker']),\n",
       " Items(items=['Aerosol cans']),\n",
       " Items(items=['Shoes']),\n",
       " Items(items=['Wet wipes']),\n",
       " Items(items=['Bodywash bottle']),\n",
       " Items(items=['Iphone']),\n",
       " Items(items=['Diaper']),\n",
       " Items(items=['Shoes']),\n",
       " Items(items=['Food blender']),\n",
       " Items(items=['Cooking pot']),\n",
       " Items(items=['TV']),\n",
       " Items(items=['Lamp']),\n",
       " Items(items=['Wooden chopsticks']),\n",
       " Items(items=['Facial cleanser bottle']),\n",
       " Items(items=['Sanitary pad']),\n",
       " Items(items=['Magazine (Glossy and non-glossy)']),\n",
       " Items(items=['Diaper']),\n",
       " Items(items=['Joss sticks']),\n",
       " Items(items=['Wet wipes']),\n",
       " Items(items=['Peanut Butter', 'Jam spread bottle', 'Coffee glass bottle']),\n",
       " Items(items=['Electric mobility scooter']),\n",
       " Items(items=['Brochure (Glossy and non-glossy)']),\n",
       " Items(items=['Lamp', 'Telephone']),\n",
       " Items(items=['Fabric']),\n",
       " Items(items=['Printer']),\n",
       " Items(items=['Absolut', 'Whisky']),\n",
       " Items(items=['Notebook']),\n",
       " Items(items=['Food glass bottle']),\n",
       " Items(items=['Glasses']),\n",
       " Items(items=['football']),\n",
       " Items(items=['Glass Tube']),\n",
       " Items(items=['Disposable shaver']),\n",
       " Items(items=['Notebook']),\n",
       " Items(items=['Glass cup']),\n",
       " Items(items=['CD player']),\n",
       " Items(items=['Bodywash bottle']),\n",
       " Items(items=['Sanitary pad', 'Disposable underpant']),\n",
       " Items(items=['9-Volt battery', 'Alkaline battery']),\n",
       " Items(items=['Gaming console']),\n",
       " Items(items=['9-Volt battery', 'Eveready']),\n",
       " Items(items=['Shampoo bottle']),\n",
       " Items(items=['Books', 'Magazine (Glossy and non-glossy)']),\n",
       " Items(items=['Shampoo bottle']),\n",
       " Items(items=['Clean aluminium foil']),\n",
       " Items(items=['Martell VSOP bottle']),\n",
       " Items(items=['Food blender']),\n",
       " Items(items=['Shoes']),\n",
       " Items(items=['Glasses']),\n",
       " Items(items=['Aerosol cans']),\n",
       " Items(items=['football']),\n",
       " Items(items=['Lamp fixture']),\n",
       " Items(items=['Sanitary pad']),\n",
       " Items(items=['Glasses']),\n",
       " Items(items=['Steel wool']),\n",
       " Items(items=['Wet wipes']),\n",
       " Items(items=['Cooking pot']),\n",
       " Items(items=['Portable charger']),\n",
       " Items(items=['DVD player', 'Audio sound system']),\n",
       " Items(items=['Battery charger']),\n",
       " Items(items=['Toaster oven']),\n",
       " Items(items=['Joss sticks']),\n",
       " Items(items=['Portable charger']),\n",
       " Items(items=['Plastic bag', 'Plastic cutlery']),\n",
       " Items(items=['Audio sound system']),\n",
       " Items(items=['Printer']),\n",
       " Items(items=['Disposable shaver']),\n",
       " Items(items=['Calendar']),\n",
       " Items(items=['Liquor bottle']),\n",
       " Items(items=['Computer mouse']),\n",
       " Items(items=['Glasses']),\n",
       " Items(items=['Diaper']),\n",
       " Items(items=['Jam spread bottle']),\n",
       " Items(items=['Rice cooker']),\n",
       " Items(items=['Joss sticks']),\n",
       " Items(items=['TV', 'Remote control']),\n",
       " Items(items=['Vase']),\n",
       " Items(items=['Shampoo bottle'])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch invoke the model, retrying after 65 seconds on rate limit error\n",
    "\n",
    "start_index = 0\n",
    "end_index = 0\n",
    "curr_tokens = 0\n",
    "\n",
    "# obtained from openai project limits based on project tier\n",
    "TPM = 30_000\n",
    "\n",
    "res = []\n",
    "\n",
    "results_csv_filename = 'results_batch3_with_similar_items.csv'\n",
    "\n",
    "while end_index < len(filenames):\n",
    "    image_path = filenames[end_index]\n",
    "    image_tokens_count = calculate_openai_image_tokens(image_path)\n",
    "    curr_tokens += system_message_tokens_count + image_prompt_tokens_count + image_tokens_count + 1024 # last constant at the end is buffer for input and output formatting + the response from the model\n",
    "\n",
    "    if curr_tokens < TPM:\n",
    "        end_index += 1\n",
    "\n",
    "    else:\n",
    "        print(f'Exceeding {TPM} TPM. Current tokens {curr_tokens}')\n",
    "        img_base64 = encode_image(image_path)\n",
    "        filenames_to_invoke = filenames[start_index: end_index]\n",
    "\n",
    "        print(\"batch invoking for filenames:\\n\", ',\\n'.join(filenames_to_invoke), end='\\n----------------------------\\n')\n",
    "\n",
    "        batch_res = batch_image_prediction_with_retry(filenames_to_invoke) # batch_res is List[Items]\n",
    "        save_to_csv(results_csv_filename, filenames_to_invoke, batch_res)\n",
    "\n",
    "        start_index = end_index\n",
    "        res.extend(batch_res)\n",
    "\n",
    "        curr_tokens = 0 # Rest token count for next batch\n",
    "\n",
    "    if end_index == len(filenames):\n",
    "        print('Last file reached.')\n",
    "        filenames_to_invoke = filenames[start_index: end_index]\n",
    "        print(\"batch invoking for filenames:\\n\", ',\\n'.join(filenames_to_invoke), end='\\n----------------------------\\n')\n",
    "\n",
    "        batch_res = batch_image_prediction_with_retry(filenames_to_invoke) # batch_res is List[Items]\n",
    "        save_to_csv(results_csv_filename, filenames_to_invoke, batch_res)\n",
    "        res.extend(batch_res)\n",
    "\n",
    "res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read results into dataframe and save to json\n",
    "Read csv results into dataframe, extract the ground truth from the filename, save to json to pass as input to LLM for similarity evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../images/test/batch3/Newsletter (4).jpeg</td>\n",
       "      <td>['Newsletter']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../images/test/batch3/Textbooks (3).jpg</td>\n",
       "      <td>['Books']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../images/test/batch3/Disposable spoon (3).jpg</td>\n",
       "      <td>['Disposable spoon']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../images/test/batch3/Computer mouse (2).jpg</td>\n",
       "      <td>['Computer mouse']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../images/test/batch3/bodywash bottle (3).jpeg</td>\n",
       "      <td>['Soap bottle', 'Shampoo bottle', 'Body lotion...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         filename  \\\n",
       "0       ../images/test/batch3/Newsletter (4).jpeg   \n",
       "1         ../images/test/batch3/Textbooks (3).jpg   \n",
       "2  ../images/test/batch3/Disposable spoon (3).jpg   \n",
       "3    ../images/test/batch3/Computer mouse (2).jpg   \n",
       "4  ../images/test/batch3/bodywash bottle (3).jpeg   \n",
       "\n",
       "                                         predictions  \n",
       "0                                     ['Newsletter']  \n",
       "1                                          ['Books']  \n",
       "2                               ['Disposable spoon']  \n",
       "3                                 ['Computer mouse']  \n",
       "4  ['Soap bottle', 'Shampoo bottle', 'Body lotion...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put results into dataframe\n",
    "import pandas as pd\n",
    "df = pd.read_csv('results_batch3_with_similar_items.csv')\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "- Extract the ground truth from the filename\n",
    "- Save to json\n",
    "- Pass to LLM for evaluation\n",
    "- Save results into dataframe\n",
    "- Export dataframe to csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>predictions</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../images/test/batch3/Newsletter (4).jpeg</td>\n",
       "      <td>['Newsletter']</td>\n",
       "      <td>Newsletter (4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../images/test/batch3/Textbooks (3).jpg</td>\n",
       "      <td>['Books']</td>\n",
       "      <td>Textbooks (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../images/test/batch3/Disposable spoon (3).jpg</td>\n",
       "      <td>['Disposable spoon']</td>\n",
       "      <td>Disposable spoon (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../images/test/batch3/Computer mouse (2).jpg</td>\n",
       "      <td>['Computer mouse']</td>\n",
       "      <td>Computer mouse (2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../images/test/batch3/bodywash bottle (3).jpeg</td>\n",
       "      <td>['Soap bottle', 'Shampoo bottle', 'Body lotion...</td>\n",
       "      <td>bodywash bottle (3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         filename  \\\n",
       "0       ../images/test/batch3/Newsletter (4).jpeg   \n",
       "1         ../images/test/batch3/Textbooks (3).jpg   \n",
       "2  ../images/test/batch3/Disposable spoon (3).jpg   \n",
       "3    ../images/test/batch3/Computer mouse (2).jpg   \n",
       "4  ../images/test/batch3/bodywash bottle (3).jpeg   \n",
       "\n",
       "                                         predictions          ground_truth  \n",
       "0                                     ['Newsletter']        Newsletter (4)  \n",
       "1                                          ['Books']         Textbooks (3)  \n",
       "2                               ['Disposable spoon']  Disposable spoon (3)  \n",
       "3                                 ['Computer mouse']    Computer mouse (2)  \n",
       "4  ['Soap bottle', 'Shampoo bottle', 'Body lotion...   bodywash bottle (3)  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "df['ground_truth'] = df['filename'].apply(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>predictions</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../images/test/batch3/Newsletter (4).jpeg</td>\n",
       "      <td>['Newsletter']</td>\n",
       "      <td>Newsletter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../images/test/batch3/Textbooks (3).jpg</td>\n",
       "      <td>['Books']</td>\n",
       "      <td>Textbooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../images/test/batch3/Disposable spoon (3).jpg</td>\n",
       "      <td>['Disposable spoon']</td>\n",
       "      <td>Disposable spoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../images/test/batch3/Computer mouse (2).jpg</td>\n",
       "      <td>['Computer mouse']</td>\n",
       "      <td>Computer mouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../images/test/batch3/bodywash bottle (3).jpeg</td>\n",
       "      <td>['Soap bottle', 'Shampoo bottle', 'Body lotion...</td>\n",
       "      <td>bodywash bottle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         filename  \\\n",
       "0       ../images/test/batch3/Newsletter (4).jpeg   \n",
       "1         ../images/test/batch3/Textbooks (3).jpg   \n",
       "2  ../images/test/batch3/Disposable spoon (3).jpg   \n",
       "3    ../images/test/batch3/Computer mouse (2).jpg   \n",
       "4  ../images/test/batch3/bodywash bottle (3).jpeg   \n",
       "\n",
       "                                         predictions      ground_truth  \n",
       "0                                     ['Newsletter']        Newsletter  \n",
       "1                                          ['Books']         Textbooks  \n",
       "2                               ['Disposable spoon']  Disposable spoon  \n",
       "3                                 ['Computer mouse']    Computer mouse  \n",
       "4  ['Soap bottle', 'Shampoo bottle', 'Body lotion...   bodywash bottle  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # This regex removes a trailing space followed by parentheses containing only digits\n",
    "    return re.sub(r'\\s+\\(\\d+\\)$', '', text)\n",
    "\n",
    "# Example usage:\n",
    "df['ground_truth'] = df['ground_truth'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ground_truth', 'predictions']].to_json('results_batch3_with_similar_items.json', orient='records')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ground_truth': 'Newsletter', 'predictions': \"['Newsletter']\"},\n",
       " {'ground_truth': 'Textbooks', 'predictions': \"['Books']\"},\n",
       " {'ground_truth': 'Disposable spoon', 'predictions': \"['Disposable spoon']\"},\n",
       " {'ground_truth': 'Computer mouse', 'predictions': \"['Computer mouse']\"},\n",
       " {'ground_truth': 'bodywash bottle',\n",
       "  'predictions': \"['Soap bottle', 'Shampoo bottle', 'Body lotion bottle']\"}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# Open the JSON file and read its contents into a string\n",
    "with open('results_batch3_with_similar_items.json', 'r') as file:\n",
    "    result_list = json.load(file)\n",
    "\n",
    "# Now result_list contains the contents of the JSON file as a string\n",
    "result_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ground_truth': 'Newsletter', 'predictions': \"['Newsletter']\"}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use chat model or LLM to evaluate the predictions accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the json output\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Similarity(BaseModel):\n",
    "    similarity: float = Field(description=\"List of similarity score of the pair of prediction and the corresponding ground truth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "qa_model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "qa_model_json_output = qa_model.with_structured_output(\n",
    "    Similarity, method=\"json_mode\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = \"\"\" \n",
    "You are given a JSON input with the following schema:\n",
    "{{\n",
    "    \"ground_truth\": str,\n",
    "    \"prediction\": List[str]\n",
    "}}\n",
    "\n",
    "Please evaluate the similarity of the ground truth and the model's prediction and return the similarity as a float between 0 and 1.0. \n",
    "\n",
    "Return the result as a JSON output according to the following schema:\n",
    "{{\n",
    "    \"similarity\": float\n",
    "}}\n",
    "\n",
    "Examples of how to calculate similarity:\n",
    "Example 1\n",
    "Given:\n",
    "{{\n",
    "    \"ground_truth\": \"Shampoo bottle\",\n",
    "    \"prediction\": [\"Shampoo bottle\", \"Conditioner Bottle\"]\n",
    "}}\n",
    "\n",
    "Expected output:\n",
    "{{\n",
    "    \"similarity\": 1.0\n",
    "}}\n",
    "\n",
    "Example 2\n",
    "Given:\n",
    "{{\n",
    "    \"ground_truth\": \"Paper cup\",\n",
    "    \"prediction\": [\"Paper cup\"]\n",
    "}}\n",
    "\n",
    "Expected output:\n",
    "{{\n",
    "    \"similarity\": 1.0\n",
    "}}\n",
    "\n",
    "Example 3\n",
    "Given:\n",
    "{{\n",
    "    \"ground_truth\": \"Paper cup\",\n",
    "    \"prediction\": [\"Plastic cup\"]\n",
    "}}\n",
    "\n",
    "Expected output:\n",
    "{{\n",
    "    \"similarity\": 0.0\n",
    "}}\n",
    "\n",
    "Example 4\n",
    "Given:\n",
    "{{\n",
    "    \"ground_truth\": \"Milk bottle\",\n",
    "    \"prediction\": [\"Bottled milk\"]\n",
    "}}\n",
    "\n",
    "Expected output:\n",
    "{{\n",
    "    \"similarity\": 1.0\n",
    "}}\n",
    "\n",
    "Example 5\n",
    "Given:\n",
    "{{\n",
    "    \"ground_truth\": \"Plastic packaging with bubble wrap\",\n",
    "    \"prediction\": [\"Bubble wrap\"]\n",
    "}}\n",
    "\n",
    "Expected output:\n",
    "{{\n",
    "    \"similarity\": 0.5\n",
    "}}\n",
    "\n",
    "\n",
    "Here is the JSON input: {ground_truth_prediction_json}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "chain = prompt_template | qa_model_json_output\n",
    "\n",
    "# @retry_after_delay\n",
    "# def batch_evaluate(json_input):\n",
    "#     eval_res = chain.invoke({\"json_input\": json_input})\n",
    "#     return eval_res\n",
    "# eval_res = chain.invoke({\"json_input\": result_list})\n",
    "# eval_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ground_truth': 'Newsletter', 'prediction': \"['Newsletter']\"},\n",
       " {'ground_truth': 'Textbooks', 'prediction': \"['Books']\"},\n",
       " {'ground_truth': 'Disposable spoon', 'prediction': \"['Disposable spoon']\"},\n",
       " {'ground_truth': 'Computer mouse', 'prediction': \"['Computer mouse']\"},\n",
       " {'ground_truth': 'bodywash bottle',\n",
       "  'prediction': \"['Soap bottle', 'Shampoo bottle', 'Body lotion bottle']\"}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_prediction_json_list = [{\"ground_truth\": ground_truth, \"prediction\": prediction} for ground_truth, prediction in zip(df['ground_truth'], df['predictions'])]\n",
    "ground_truth_prediction_json_list[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = chain.batch([{'ground_truth_prediction_json': ground_truth_prediction_json} for ground_truth_prediction_json in ground_truth_prediction_json_list[:5]])\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry_after_delay\n",
    "def batch_invoke_evaluate(ground_truth_prediction_json_list, **kwargs):\n",
    "    batch_res = chain.batch([{'ground_truth_prediction_json': ground_truth_prediction_json} for ground_truth_prediction_json in ground_truth_prediction_json_list])\n",
    "\n",
    "    return batch_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint save to csv\n",
    "import csv\n",
    "def save_to_csv(csv_filename: str, ground_truth_prediction_json_list: List[str], res: List[Similarity]):\n",
    "    file_exists = os.path.exists(csv_filename)\n",
    "    new_rows = [(ground_truth_prediction_json, res.similarity) for ground_truth_prediction_json, res in zip(ground_truth_prediction_json_list, res)]\n",
    "    with open(csv_filename, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            writer.writerow(['ground_truth_prediction_json', 'similarity'])\n",
    "        writer.writerows(new_rows)\n",
    "\n",
    "    print(f'Saved {len(ground_truth_prediction_json_list)} rows to {csv_filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceeding 60000 TPM. Current tokens 60871. Start index 0. End index 44\n",
      "Saved 44 rows to evaluation_results_batch3_with_similar_items.csv\n",
      "Exceeding 60000 TPM. Current tokens 60877. Start index 44. End index 88\n",
      "Saved 44 rows to evaluation_results_batch3_with_similar_items.csv\n",
      "Exceeding 60000 TPM. Current tokens 60919. Start index 88. End index 132\n",
      "Saved 44 rows to evaluation_results_batch3_with_similar_items.csv\n",
      "Last file reached.\n",
      "Saved 22 rows to evaluation_results_batch3_with_similar_items.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.6666666666666666),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.5),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.5),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.6666666666666666),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.5),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.5),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.5),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.3333333333333333),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.5),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.5),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0),\n",
       " Similarity(similarity=1.0),\n",
       " Similarity(similarity=0.0)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch invoke the model, retrying after 65 seconds on rate limit error\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_name_for_model('gpt-3.5-turbo')\n",
    "\n",
    "start_index = 0\n",
    "end_index = 0\n",
    "curr_tokens = 0\n",
    "\n",
    "# obtained from openai project limits based on project tier\n",
    "TPM = 60_000\n",
    "\n",
    "res = []\n",
    "\n",
    "results_csv_filename = 'evaluation_results_batch3_with_similar_items.csv'\n",
    "\n",
    "while end_index < len(ground_truth_prediction_json_list):\n",
    "    ground_truth_prediction_json = ground_truth_prediction_json_list[end_index]\n",
    "    prompt_tokens_count = num_tokens_from_string(prompt_template.format(ground_truth_prediction_json=ground_truth_prediction_json), encoding)\n",
    "\n",
    "    curr_tokens += prompt_tokens_count + 1024 # last constant at the end is buffer for input and output formatting + the response from the model\n",
    "\n",
    "    if curr_tokens < TPM:\n",
    "        end_index += 1\n",
    "\n",
    "    else:\n",
    "        print(f'Exceeding {TPM} TPM. Current tokens {curr_tokens}. Start index {start_index}. End index {end_index}')\n",
    "        batch_to_invoke = ground_truth_prediction_json_list[start_index: end_index]\n",
    "\n",
    "        batch_res = batch_invoke_evaluate(batch_to_invoke) # batch_res is List[Items]\n",
    "        save_to_csv(results_csv_filename, batch_to_invoke, batch_res)\n",
    "\n",
    "        start_index = end_index\n",
    "        res.extend(batch_res)\n",
    "\n",
    "        curr_tokens = 0 # Rest token count for next batch\n",
    "\n",
    "    if end_index == len(ground_truth_prediction_json_list):\n",
    "        print('Last file reached.')\n",
    "        batch_to_invoke = ground_truth_prediction_json_list[start_index: end_index]\n",
    "        batch_res = batch_invoke_evaluate(batch_to_invoke) # batch_res is List[Items]\n",
    "        save_to_csv(results_csv_filename, batch_to_invoke, batch_res)\n",
    "        res.extend(batch_res)\n",
    "\n",
    "res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "put similarity into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>predictions</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../images/test/batch3/Newsletter (4).jpeg</td>\n",
       "      <td>['Newsletter']</td>\n",
       "      <td>Newsletter</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../images/test/batch3/Textbooks (3).jpg</td>\n",
       "      <td>['Books']</td>\n",
       "      <td>Textbooks</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../images/test/batch3/Disposable spoon (3).jpg</td>\n",
       "      <td>['Disposable spoon']</td>\n",
       "      <td>Disposable spoon</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../images/test/batch3/Computer mouse (2).jpg</td>\n",
       "      <td>['Computer mouse']</td>\n",
       "      <td>Computer mouse</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../images/test/batch3/bodywash bottle (3).jpeg</td>\n",
       "      <td>['Soap bottle', 'Shampoo bottle', 'Body lotion...</td>\n",
       "      <td>bodywash bottle</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         filename  \\\n",
       "0       ../images/test/batch3/Newsletter (4).jpeg   \n",
       "1         ../images/test/batch3/Textbooks (3).jpg   \n",
       "2  ../images/test/batch3/Disposable spoon (3).jpg   \n",
       "3    ../images/test/batch3/Computer mouse (2).jpg   \n",
       "4  ../images/test/batch3/bodywash bottle (3).jpeg   \n",
       "\n",
       "                                         predictions      ground_truth  \\\n",
       "0                                     ['Newsletter']        Newsletter   \n",
       "1                                          ['Books']         Textbooks   \n",
       "2                               ['Disposable spoon']  Disposable spoon   \n",
       "3                                 ['Computer mouse']    Computer mouse   \n",
       "4  ['Soap bottle', 'Shampoo bottle', 'Body lotion...   bodywash bottle   \n",
       "\n",
       "   similarity  \n",
       "0         1.0  \n",
       "1         0.0  \n",
       "2         1.0  \n",
       "3         1.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['similarity'] = [r.similarity for r in res]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output to csv for manual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['filename', 'ground_truth', 'predictions', 'similarity']].to_csv('manual_evaluation_batch3_with_similar_items.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put similar items into new entries in the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "len(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_items = set()\n",
    "res = []\n",
    "for item in data:\n",
    "    item_name = item['item']\n",
    "    item_name = item_name.strip()\n",
    "    item_name = item_name.capitalize()\n",
    "    if item_name not in unique_items:\n",
    "        res.append({\n",
    "        'material': item['material'],\n",
    "        'item': item['item'],\n",
    "        'recyclable': item['recyclable'],\n",
    "        'instructions': item['instructions']\n",
    "        })\n",
    "        unique_items.add(item_name)\n",
    "\n",
    "    for similar_item in item['similar_items']:\n",
    "        similar_item = similar_item.strip()\n",
    "        similar_item = similar_item.capitalize()\n",
    "        if similar_item not in unique_items:\n",
    "            res.append({\n",
    "                'material': item['material'],\n",
    "                'item': similar_item,\n",
    "                'recyclable': item['recyclable'],\n",
    "                'instructions': item['instructions']\n",
    "            })\n",
    "            unique_items.add(similar_item)\n",
    "\n",
    "\n",
    "len(res)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_res = sorted(res, key=lambda item: item['item'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cleaned_data.json', 'w') as file:\n",
    "    json.dump(sorted_res, file, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
